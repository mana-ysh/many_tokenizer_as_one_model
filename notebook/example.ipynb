{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n",
    "from allennlp.data.iterators import BucketIterator\n",
    "from allennlp.predictors import SentenceTaggerPredictor\n",
    "from allennlp.training.trainer import Trainer\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multi_criterion_dataset_reader import MultiCriterionDatasetReader\n",
    "from multi_criterion_tokenizer import MultiCriterionTokenizer\n",
    "from tokenize_predictor import TokenizePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reader = MultiCriterionDatasetReader()\n",
    "train_dataset = reader.read(cached_path(\n",
    "    '../data/sample/train_dataset.json'))\n",
    "vocab = Vocabulary.from_instances(train_dataset)\n",
    "\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6\n",
    "\n",
    "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
    "                            embedding_dim=EMBEDDING_DIM)\n",
    "criterion_embedding = Embedding(num_embeddings=7, embedding_dim=EMBEDDING_DIM)  # FIXME: num embeddings\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})\n",
    "lstm = PytorchSeq2SeqWrapper(torch.nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, batch_first=True))\n",
    "model = MultiCriterionTokenizer(word_embeddings, criterion_embedding, lstm, vocab)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "iterator = BucketIterator(batch_size=1, sorting_keys=[(\"sentence\", \"num_tokens\")])\n",
    "iterator.index_with(vocab)\n",
    "trainer = Trainer(model=model,\n",
    "                  optimizer=optimizer,\n",
    "                  iterator=iterator,\n",
    "                  train_dataset=train_dataset,\n",
    "                  patience=10,\n",
    "                  num_epochs=100,\n",
    "                  cuda_device=-1)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TokenizePredictor(model, dataset_reader=reader)\n",
    "predictor.predict(\"選挙管理委員会\", \"sudachib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
